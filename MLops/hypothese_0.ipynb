{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c5005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark==3.0.3 in ./.local/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: py4j==0.10.9 in ./.local/lib/python3.8/site-packages (from pyspark==3.0.3) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "# Установка pyspark\n",
    "!pip install pyspark==3.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3888de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Библиотеки\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "from pyspark.sql.types import TimestampType, FloatType, StringType\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d9c96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список файлов в bucket\n",
    "cmd = \"hdfs dfs -ls s3a://cherepanov-bucket-new/\"\n",
    "files = subprocess.check_output(cmd, shell=True).decode(\"utf-8\").split(\"\\n\")\n",
    "files = [f.split(\" \")[-1] for f in files if \".txt\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d7bfde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем сессию spark\n",
    "spark = SparkSession.builder.config(\"spark.hadoop.fs.s3a.access.key\", \"YCAJEu8SE1sWgkwmzquSB8ktL\") \\\n",
    "                              .config(\"spark.hadoop.fs.s3a.secret.key\", \"YCM7SiqO1z6BNvoU4mgEqZyg_PphP0IQnncQ8lkz\") \\\n",
    "                              .config(\"spark.hadoop.fs.endpoint\", \"storage.yandexcloud.net\") \\\n",
    "                              .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf869603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем схему данных\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"tranaction_id\", IntegerType(), True),\n",
    "        StructField(\"tx_datetime\", TimestampType(), True),\n",
    "        StructField(\"customer_id\", IntegerType(), True),\n",
    "        StructField(\"terminal_id\", IntegerType(), True),\n",
    "        StructField(\"tx_amount\", FloatType(), True),\n",
    "        StructField(\"tx_time_seconds\", IntegerType(), True),\n",
    "        StructField(\"tx_time_days\", IntegerType(), True),\n",
    "        StructField(\"tx_fraud\", IntegerType(), True),\n",
    "        StructField(\"tx_fraud_scenario\", IntegerType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5293e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|            0|2019-08-22 06:51:03|          0|        711|    70.91|          24663|           0|       0|                0|\n",
      "|            1|2019-08-22 05:10:37|          0|          0|    90.55|          18637|           0|       0|                0|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Прочитаем первый csv для его анализа\n",
    "df = spark.read.format(\"csv\") \\\n",
    "                 .schema(schema) \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .option(\"sep\", \",\") \\\n",
    "                 .load(files[0])\n",
    "df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42fb06c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tranaction_id: integer (nullable = true)\n",
      " |-- tx_datetime: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- terminal_id: integer (nullable = true)\n",
      " |-- tx_amount: float (nullable = true)\n",
      " |-- tx_time_seconds: integer (nullable = true)\n",
      " |-- tx_time_days: integer (nullable = true)\n",
      " |-- tx_fraud: integer (nullable = true)\n",
      " |-- tx_fraud_scenario: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af90563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# список имен колонок\n",
    "cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bccae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tranaction_id', 0),\n",
       " ('tx_datetime', 100),\n",
       " ('customer_id', 0),\n",
       " ('terminal_id', 0),\n",
       " ('tx_amount', 0),\n",
       " ('tx_time_seconds', 0),\n",
       " ('tx_time_days', 0),\n",
       " ('tx_fraud', 0),\n",
       " ('tx_fraud_scenario', 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем NaN\n",
    "columns_has_null = [(col, df.filter(df[col].isNull()).count()) for col in cols]\n",
    "columns_has_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "132dc060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46988318"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем строки с пропусками\n",
    "df2 = df.na.drop()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "945e3ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46988137 46988318\n"
     ]
    }
   ],
   "source": [
    "# считаем дубли\n",
    "counts_df = df2.select(\n",
    "    [\n",
    "        countDistinct(*cols).alias('n_unique'),\n",
    "        count('*').alias('n_rows')\n",
    "    ]\n",
    ")\n",
    "n_unique, n_rows = counts_df.collect()[0]\n",
    "print(n_unique, n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "117ef2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46988137"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем дубли\n",
    "df3 = df2.drop_duplicates()\n",
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697fcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Останавливаем работу spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
