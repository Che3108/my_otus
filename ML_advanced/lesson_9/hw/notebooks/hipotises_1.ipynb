{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сменим рабочую дирректорию для удобства\n",
    "import os\n",
    "os.chdir('/home/slawa/HDD/my_scripts/my_otus/ML_advanced/lesson_9/hw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0      52    1   0       125   212    0        1      168      0      1.0   \n",
       "1      53    1   0       140   203    1        0      155      1      3.1   \n",
       "2      70    1   0       145   174    0        1      125      1      2.6   \n",
       "3      61    1   0       148   203    0        1      161      0      0.0   \n",
       "4      62    0   0       138   294    1        1      106      0      1.9   \n",
       "...   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "1020   59    1   1       140   221    0        1      164      1      0.0   \n",
       "1021   60    1   0       125   258    0        0      141      1      2.8   \n",
       "1022   47    1   0       110   275    0        0      118      1      1.0   \n",
       "1023   50    0   0       110   254    0        0      159      0      0.0   \n",
       "1024   54    1   0       120   188    0        1      113      0      1.4   \n",
       "\n",
       "      slope  ca  thal  target  \n",
       "0         2   2     3       0  \n",
       "1         0   0     3       0  \n",
       "2         0   0     3       0  \n",
       "3         2   1     3       0  \n",
       "4         1   3     2       0  \n",
       "...     ...  ..   ...     ...  \n",
       "1020      2   0     2       1  \n",
       "1021      1   1     3       0  \n",
       "1022      1   1     2       0  \n",
       "1023      2   0     2       1  \n",
       "1024      1   1     3       0  \n",
       "\n",
       "[1025 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем данные\n",
    "raw_data_file_name = 'data/raw_data/heart.csv'\n",
    "raw_data = pd.read_csv(raw_data_file_name, delimiter=',', decimal='.')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем дубликаты\n",
    "raw_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем мусорные данные\n",
    "raw_data.drop(raw_data.loc[raw_data['thal'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 3: count 117, percent 39.00%\n",
      "class 2: count 165, percent 55.00%\n",
      "class 1: count 18, percent 6.00%\n"
     ]
    }
   ],
   "source": [
    "# считаем баланс классов\n",
    "for thal in raw_data['thal'].unique():\n",
    "    count = raw_data.loc[raw_data['thal'] == thal].shape[0]\n",
    "    count_percent = count / raw_data.shape[0] * 100\n",
    "    print(f'class {thal}: count {count}, percent {count_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прячем часть данных для финальной проверки\n",
    "data_train, data_test = train_test_split(raw_data, test_size=0.1, stratify=raw_data['thal'])\n",
    "data_test.to_csv('data/test_data/test_clear_disbalance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 2: count 149, percent 55.19%\n",
      "class 3: count 105, percent 38.89%\n",
      "class 1: count 16, percent 5.93%\n"
     ]
    }
   ],
   "source": [
    "# считаем баланс классов в оставшемся датасете\n",
    "for thal in data_train['thal'].unique():\n",
    "    count = data_train.loc[data_train['thal'] == thal].shape[0]\n",
    "    count_percent = count / data_train.shape[0] * 100\n",
    "    print(f'class {thal}: count {count}, percent {count_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# бьем оставшуюся выборку\n",
    "df_train, df_test = train_test_split(data_train, test_size=0.2, stratify=data_train['thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 3: count 84, percent 38.89%\n",
      "class 1: count 13, percent 6.02%\n",
      "class 2: count 119, percent 55.09%\n"
     ]
    }
   ],
   "source": [
    "# считаем баланс классов в оставшемся датасете\n",
    "for thal in df_train['thal'].unique():\n",
    "    count = df_train.loc[df_train['thal'] == thal].shape[0]\n",
    "    count_percent = count / df_train.shape[0] * 100\n",
    "    print(f'class {thal}: count {count}, percent {count_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем поля по их типам\n",
    "target_col = ['thal']\n",
    "categorical_col = ['cp', 'restecg', 'slope']\n",
    "numeric_col = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
    "binary_col = ['sex', 'fbs', 'exang', 'target']\n",
    "all_features = categorical_col + numeric_col + binary_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: X(216, 13), Y(216, 1)\n",
      "test: X(54, 13), Y(54, 1)\n"
     ]
    }
   ],
   "source": [
    "# собираем данные для обучения\n",
    "X_train_df = df_train[all_features]\n",
    "Y_train_df = df_train[target_col]\n",
    "X_test_df = df_test[all_features]\n",
    "Y_test_df = df_test[target_col]\n",
    "print(f'train: X{X_train_df.shape}, Y{Y_train_df.shape}')\n",
    "print(f'test: X{X_test_df.shape}, Y{Y_test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем конвейер предобработки данных\n",
    "data_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_col),\n",
    "        ('scaler', StandardScaler(), numeric_col),\n",
    "        (\"as_is\", \"passthrough\", binary_col)\n",
    "    ]\n",
    ")\n",
    "preprocessor = Pipeline(steps=[(\"data_transformer\", data_transformer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;data_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;cp&#x27;, &#x27;restecg&#x27;, &#x27;slope&#x27;]),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;ca&#x27;]),\n",
       "                                                 (&#x27;as_is&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;target&#x27;])]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;data_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;cp&#x27;, &#x27;restecg&#x27;, &#x27;slope&#x27;]),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;,\n",
       "                                                   &#x27;ca&#x27;]),\n",
       "                                                 (&#x27;as_is&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;,\n",
       "                                                   &#x27;target&#x27;])]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;data_transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for data_transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;cp&#x27;, &#x27;restecg&#x27;, &#x27;slope&#x27;]),\n",
       "                                (&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;,\n",
       "                                  &#x27;oldpeak&#x27;, &#x27;ca&#x27;]),\n",
       "                                (&#x27;as_is&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;, &#x27;target&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehot</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;cp&#x27;, &#x27;restecg&#x27;, &#x27;slope&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">scaler</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;, &#x27;oldpeak&#x27;, &#x27;ca&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">as_is</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;, &#x27;target&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">passthrough</label><div class=\"sk-toggleable__content fitted\"><pre>passthrough</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data_transformer',\n",
       "                 ColumnTransformer(transformers=[('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['cp', 'restecg', 'slope']),\n",
       "                                                 ('scaler', StandardScaler(),\n",
       "                                                  ['age', 'trestbps', 'chol',\n",
       "                                                   'thalach', 'oldpeak',\n",
       "                                                   'ca']),\n",
       "                                                 ('as_is', 'passthrough',\n",
       "                                                  ['sex', 'fbs', 'exang',\n",
       "                                                   'target'])]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем препроцессор\n",
    "preprocessor.fit(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# трансформируем данные для обучения в массив\n",
    "X_train_array = preprocessor.transform(X_train_df)\n",
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 20)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# трансформируем данные для теста в массив\n",
    "X_test_array = preprocessor.transform(X_test_df)\n",
    "X_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 20)\n",
      "(51, 20)\n"
     ]
    }
   ],
   "source": [
    "# Данные для ae\n",
    "X_train_array_ae = preprocessor.transform(X_train_df.drop(Y_train_df[Y_train_df['thal'] == 1].index))\n",
    "X_test_array_ae = preprocessor.transform(X_test_df.drop(Y_test_df[Y_test_df['thal'] == 1].index))\n",
    "print(X_train_array_ae.shape)\n",
    "print(X_test_array_ae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 03:13:37.498356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-05 03:13:43.158832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l1_l2, l1, l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import mae\n",
    "from tensorflow.keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ch = ModelCheckpoint(\n",
    "    'models/ae.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 03:13:46.454252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.471854: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.472023: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.472902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.473033: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.473147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.540507: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.540704: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.540826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 03:13:46.540913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,970</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,980</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m8,970\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m8,980\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,950</span> (70.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,950\u001b[0m (70.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,926</span> (66.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,926\u001b[0m (66.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent = 10\n",
    "\n",
    "en_in = Input((X_train_array.shape[1],))\n",
    "en_x = Dense(256, activation='relu', kernel_regularizer=l2)(en_in)\n",
    "en_x = BatchNormalization()(en_x)\n",
    "en_out = Dense(latent)(en_x)\n",
    "en = Model(en_in, en_out) \n",
    "\n",
    "dec_in = Input((latent,))\n",
    "dec_x = Dense(256, activation='relu', kernel_regularizer=l2)(dec_in)\n",
    "dec_x = BatchNormalization()(dec_x)\n",
    "dec_out = Dense(X_train_array.shape[1])(dec_x)\n",
    "dec = Model(dec_in, dec_out) \n",
    "\n",
    "ae = Model(en_in, dec(en(en_in)))\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.compile(loss='mse', optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712258027.809927 2023063 service.cc:145] XLA service 0x72e30400c340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1712258027.809943 2023063 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2060 SUPER, Compute Capability 7.5\n",
      "2024-04-05 03:13:47.842646: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-05 03:13:47.980883: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 2.9436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1712258028.619486 2023063 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 2.8005\n",
      "Epoch 1: val_loss improved from inf to 1.05810, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - loss: 2.7942 - val_loss: 1.0581\n",
      "Epoch 2/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5000\n",
      "Epoch 2: val_loss improved from 1.05810 to 1.05244, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4705 - val_loss: 1.0524\n",
      "Epoch 3/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2600\n",
      "Epoch 3: val_loss improved from 1.05244 to 1.04756, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2486 - val_loss: 1.0476\n",
      "Epoch 4/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9927\n",
      "Epoch 4: val_loss improved from 1.04756 to 1.04315, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0142 - val_loss: 1.0432\n",
      "Epoch 5/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8595\n",
      "Epoch 5: val_loss improved from 1.04315 to 1.03912, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8704 - val_loss: 1.0391\n",
      "Epoch 6/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6527\n",
      "Epoch 6: val_loss improved from 1.03912 to 1.03585, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7104 - val_loss: 1.0359\n",
      "Epoch 7/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6516\n",
      "Epoch 7: val_loss improved from 1.03585 to 1.03267, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6025 - val_loss: 1.0327\n",
      "Epoch 8/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5483\n",
      "Epoch 8: val_loss improved from 1.03267 to 1.02993, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5437 - val_loss: 1.0299\n",
      "Epoch 9/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4983\n",
      "Epoch 9: val_loss improved from 1.02993 to 1.02705, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4554 - val_loss: 1.0271\n",
      "Epoch 10/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5388\n",
      "Epoch 10: val_loss improved from 1.02705 to 1.02355, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4110 - val_loss: 1.0235\n",
      "Epoch 11/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2912\n",
      "Epoch 11: val_loss improved from 1.02355 to 1.02009, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3327 - val_loss: 1.0201\n",
      "Epoch 12/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2560\n",
      "Epoch 12: val_loss improved from 1.02009 to 1.01622, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2844 - val_loss: 1.0162\n",
      "Epoch 13/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2259\n",
      "Epoch 13: val_loss improved from 1.01622 to 1.01148, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2428 - val_loss: 1.0115\n",
      "Epoch 14/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2579\n",
      "Epoch 14: val_loss improved from 1.01148 to 1.00698, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2265 - val_loss: 1.0070\n",
      "Epoch 15/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2608\n",
      "Epoch 15: val_loss improved from 1.00698 to 1.00149, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1954 - val_loss: 1.0015\n",
      "Epoch 16/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1646\n",
      "Epoch 16: val_loss improved from 1.00149 to 0.99628, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1648 - val_loss: 0.9963\n",
      "Epoch 17/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1707\n",
      "Epoch 17: val_loss improved from 0.99628 to 0.99067, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1439 - val_loss: 0.9907\n",
      "Epoch 18/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1117\n",
      "Epoch 18: val_loss improved from 0.99067 to 0.98446, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0963 - val_loss: 0.9845\n",
      "Epoch 19/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0771\n",
      "Epoch 19: val_loss improved from 0.98446 to 0.97737, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0967 - val_loss: 0.9774\n",
      "Epoch 20/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0493\n",
      "Epoch 20: val_loss improved from 0.97737 to 0.96997, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0571 - val_loss: 0.9700\n",
      "Epoch 21/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0665\n",
      "Epoch 21: val_loss improved from 0.96997 to 0.96149, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0469 - val_loss: 0.9615\n",
      "Epoch 22/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0411\n",
      "Epoch 22: val_loss improved from 0.96149 to 0.95467, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0272 - val_loss: 0.9547\n",
      "Epoch 23/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0816\n",
      "Epoch 23: val_loss improved from 0.95467 to 0.94714, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0383 - val_loss: 0.9471\n",
      "Epoch 24/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0415\n",
      "Epoch 24: val_loss improved from 0.94714 to 0.93952, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0067 - val_loss: 0.9395\n",
      "Epoch 25/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0058\n",
      "Epoch 25: val_loss improved from 0.93952 to 0.93159, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9994 - val_loss: 0.9316\n",
      "Epoch 26/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9049\n",
      "Epoch 26: val_loss improved from 0.93159 to 0.92290, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9627 - val_loss: 0.9229\n",
      "Epoch 27/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9886\n",
      "Epoch 27: val_loss improved from 0.92290 to 0.91453, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9595 - val_loss: 0.9145\n",
      "Epoch 28/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0041\n",
      "Epoch 28: val_loss improved from 0.91453 to 0.90643, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9739 - val_loss: 0.9064\n",
      "Epoch 29/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9334\n",
      "Epoch 29: val_loss improved from 0.90643 to 0.89739, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9380 - val_loss: 0.8974\n",
      "Epoch 30/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9691\n",
      "Epoch 30: val_loss improved from 0.89739 to 0.88931, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9510 - val_loss: 0.8893\n",
      "Epoch 31/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9216\n",
      "Epoch 31: val_loss improved from 0.88931 to 0.88225, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9215 - val_loss: 0.8822\n",
      "Epoch 32/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9435\n",
      "Epoch 32: val_loss improved from 0.88225 to 0.87614, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9273 - val_loss: 0.8761\n",
      "Epoch 33/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9091\n",
      "Epoch 33: val_loss improved from 0.87614 to 0.86968, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9195 - val_loss: 0.8697\n",
      "Epoch 34/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8733\n",
      "Epoch 34: val_loss improved from 0.86968 to 0.86479, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8954 - val_loss: 0.8648\n",
      "Epoch 35/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9033\n",
      "Epoch 35: val_loss improved from 0.86479 to 0.86017, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9000 - val_loss: 0.8602\n",
      "Epoch 36/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8780\n",
      "Epoch 36: val_loss improved from 0.86017 to 0.85561, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8956 - val_loss: 0.8556\n",
      "Epoch 37/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8515\n",
      "Epoch 37: val_loss improved from 0.85561 to 0.85038, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8600 - val_loss: 0.8504\n",
      "Epoch 38/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8464\n",
      "Epoch 38: val_loss improved from 0.85038 to 0.84523, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8662 - val_loss: 0.8452\n",
      "Epoch 39/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8576\n",
      "Epoch 39: val_loss improved from 0.84523 to 0.84085, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8690 - val_loss: 0.8409\n",
      "Epoch 40/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8799\n",
      "Epoch 40: val_loss improved from 0.84085 to 0.83732, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8708 - val_loss: 0.8373\n",
      "Epoch 41/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8125\n",
      "Epoch 41: val_loss improved from 0.83732 to 0.83494, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8373 - val_loss: 0.8349\n",
      "Epoch 42/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8456\n",
      "Epoch 42: val_loss improved from 0.83494 to 0.83059, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8339 - val_loss: 0.8306\n",
      "Epoch 43/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7865\n",
      "Epoch 43: val_loss improved from 0.83059 to 0.82776, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8333 - val_loss: 0.8278\n",
      "Epoch 44/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8220\n",
      "Epoch 44: val_loss improved from 0.82776 to 0.82582, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8377 - val_loss: 0.8258\n",
      "Epoch 45/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8928\n",
      "Epoch 45: val_loss improved from 0.82582 to 0.82145, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8381 - val_loss: 0.8214\n",
      "Epoch 46/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7828\n",
      "Epoch 46: val_loss improved from 0.82145 to 0.81766, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8165 - val_loss: 0.8177\n",
      "Epoch 47/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7637\n",
      "Epoch 47: val_loss improved from 0.81766 to 0.81604, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8072 - val_loss: 0.8160\n",
      "Epoch 48/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8159\n",
      "Epoch 48: val_loss did not improve from 0.81604\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8236 - val_loss: 0.8168\n",
      "Epoch 49/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7920\n",
      "Epoch 49: val_loss improved from 0.81604 to 0.81560, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7996 - val_loss: 0.8156\n",
      "Epoch 50/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7761\n",
      "Epoch 50: val_loss improved from 0.81560 to 0.81222, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8090 - val_loss: 0.8122\n",
      "Epoch 51/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8051\n",
      "Epoch 51: val_loss improved from 0.81222 to 0.80994, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7931 - val_loss: 0.8099\n",
      "Epoch 52/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7924\n",
      "Epoch 52: val_loss improved from 0.80994 to 0.80629, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8012 - val_loss: 0.8063\n",
      "Epoch 53/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7995\n",
      "Epoch 53: val_loss improved from 0.80629 to 0.80289, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7935 - val_loss: 0.8029\n",
      "Epoch 54/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7680\n",
      "Epoch 54: val_loss improved from 0.80289 to 0.80116, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7745 - val_loss: 0.8012\n",
      "Epoch 55/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8760\n",
      "Epoch 55: val_loss improved from 0.80116 to 0.79901, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7983 - val_loss: 0.7990\n",
      "Epoch 56/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7501\n",
      "Epoch 56: val_loss improved from 0.79901 to 0.79640, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7657 - val_loss: 0.7964\n",
      "Epoch 57/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7474\n",
      "Epoch 57: val_loss improved from 0.79640 to 0.79342, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7636 - val_loss: 0.7934\n",
      "Epoch 58/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7616\n",
      "Epoch 58: val_loss improved from 0.79342 to 0.78856, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7586 - val_loss: 0.7886\n",
      "Epoch 59/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7398\n",
      "Epoch 59: val_loss improved from 0.78856 to 0.78648, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7515 - val_loss: 0.7865\n",
      "Epoch 60/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7549\n",
      "Epoch 60: val_loss improved from 0.78648 to 0.78271, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7538 - val_loss: 0.7827\n",
      "Epoch 61/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7440\n",
      "Epoch 61: val_loss improved from 0.78271 to 0.77864, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7463 - val_loss: 0.7786\n",
      "Epoch 62/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8230\n",
      "Epoch 62: val_loss improved from 0.77864 to 0.77557, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7628 - val_loss: 0.7756\n",
      "Epoch 63/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7493\n",
      "Epoch 63: val_loss improved from 0.77557 to 0.77434, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7558 - val_loss: 0.7743\n",
      "Epoch 64/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6795\n",
      "Epoch 64: val_loss improved from 0.77434 to 0.77229, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7358 - val_loss: 0.7723\n",
      "Epoch 65/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7142\n",
      "Epoch 65: val_loss improved from 0.77229 to 0.76688, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7363 - val_loss: 0.7669\n",
      "Epoch 66/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7440\n",
      "Epoch 66: val_loss improved from 0.76688 to 0.76386, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7374 - val_loss: 0.7639\n",
      "Epoch 67/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6875\n",
      "Epoch 67: val_loss improved from 0.76386 to 0.76214, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7366 - val_loss: 0.7621\n",
      "Epoch 68/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7063\n",
      "Epoch 68: val_loss improved from 0.76214 to 0.76046, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7306 - val_loss: 0.7605\n",
      "Epoch 69/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6984\n",
      "Epoch 69: val_loss improved from 0.76046 to 0.75771, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7205 - val_loss: 0.7577\n",
      "Epoch 70/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7538\n",
      "Epoch 70: val_loss improved from 0.75771 to 0.75318, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7272 - val_loss: 0.7532\n",
      "Epoch 71/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6991\n",
      "Epoch 71: val_loss improved from 0.75318 to 0.75094, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7211 - val_loss: 0.7509\n",
      "Epoch 72/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7235\n",
      "Epoch 72: val_loss improved from 0.75094 to 0.74777, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7149 - val_loss: 0.7478\n",
      "Epoch 73/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6830\n",
      "Epoch 73: val_loss improved from 0.74777 to 0.74573, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7101 - val_loss: 0.7457\n",
      "Epoch 74/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7288\n",
      "Epoch 74: val_loss improved from 0.74573 to 0.74401, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7111 - val_loss: 0.7440\n",
      "Epoch 75/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6664\n",
      "Epoch 75: val_loss improved from 0.74401 to 0.74225, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6952 - val_loss: 0.7422\n",
      "Epoch 76/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6833\n",
      "Epoch 76: val_loss improved from 0.74225 to 0.74072, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7017 - val_loss: 0.7407\n",
      "Epoch 77/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7002\n",
      "Epoch 77: val_loss improved from 0.74072 to 0.73979, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6952 - val_loss: 0.7398\n",
      "Epoch 78/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6670\n",
      "Epoch 78: val_loss improved from 0.73979 to 0.73647, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6882 - val_loss: 0.7365\n",
      "Epoch 79/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7224\n",
      "Epoch 79: val_loss improved from 0.73647 to 0.73403, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7104 - val_loss: 0.7340\n",
      "Epoch 80/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6844\n",
      "Epoch 80: val_loss improved from 0.73403 to 0.73072, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6764 - val_loss: 0.7307\n",
      "Epoch 81/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6513\n",
      "Epoch 81: val_loss improved from 0.73072 to 0.72726, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6823 - val_loss: 0.7273\n",
      "Epoch 82/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6896\n",
      "Epoch 82: val_loss improved from 0.72726 to 0.72549, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6880 - val_loss: 0.7255\n",
      "Epoch 83/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6622\n",
      "Epoch 83: val_loss improved from 0.72549 to 0.72221, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6701 - val_loss: 0.7222\n",
      "Epoch 84/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7120\n",
      "Epoch 84: val_loss improved from 0.72221 to 0.71814, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6820 - val_loss: 0.7181\n",
      "Epoch 85/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6821\n",
      "Epoch 85: val_loss improved from 0.71814 to 0.71519, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6756 - val_loss: 0.7152\n",
      "Epoch 86/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6907\n",
      "Epoch 86: val_loss improved from 0.71519 to 0.71241, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6822 - val_loss: 0.7124\n",
      "Epoch 87/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6682\n",
      "Epoch 87: val_loss improved from 0.71241 to 0.71071, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6801 - val_loss: 0.7107\n",
      "Epoch 88/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6564\n",
      "Epoch 88: val_loss improved from 0.71071 to 0.70772, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6640 - val_loss: 0.7077\n",
      "Epoch 89/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6751\n",
      "Epoch 89: val_loss improved from 0.70772 to 0.70676, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6878 - val_loss: 0.7068\n",
      "Epoch 90/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6551\n",
      "Epoch 90: val_loss improved from 0.70676 to 0.70424, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6670 - val_loss: 0.7042\n",
      "Epoch 91/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6131\n",
      "Epoch 91: val_loss improved from 0.70424 to 0.70185, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6639 - val_loss: 0.7019\n",
      "Epoch 92/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6429\n",
      "Epoch 92: val_loss improved from 0.70185 to 0.69841, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6706 - val_loss: 0.6984\n",
      "Epoch 93/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6603\n",
      "Epoch 93: val_loss improved from 0.69841 to 0.69628, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6604 - val_loss: 0.6963\n",
      "Epoch 94/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6388\n",
      "Epoch 94: val_loss improved from 0.69628 to 0.69439, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6545 - val_loss: 0.6944\n",
      "Epoch 95/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6553\n",
      "Epoch 95: val_loss improved from 0.69439 to 0.69223, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6549 - val_loss: 0.6922\n",
      "Epoch 96/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7041\n",
      "Epoch 96: val_loss improved from 0.69223 to 0.68978, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6676 - val_loss: 0.6898\n",
      "Epoch 97/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6200\n",
      "Epoch 97: val_loss improved from 0.68978 to 0.68831, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6619 - val_loss: 0.6883\n",
      "Epoch 98/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6426\n",
      "Epoch 98: val_loss improved from 0.68831 to 0.68701, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6577 - val_loss: 0.6870\n",
      "Epoch 99/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6423\n",
      "Epoch 99: val_loss improved from 0.68701 to 0.68481, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6404 - val_loss: 0.6848\n",
      "Epoch 100/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6494\n",
      "Epoch 100: val_loss improved from 0.68481 to 0.68325, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6558 - val_loss: 0.6833\n",
      "Epoch 101/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.6349\n",
      "Epoch 101: val_loss improved from 0.68325 to 0.68137, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6606 - val_loss: 0.6814\n",
      "Epoch 102/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6409\n",
      "Epoch 102: val_loss improved from 0.68137 to 0.67888, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6522 - val_loss: 0.6789\n",
      "Epoch 103/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6100\n",
      "Epoch 103: val_loss improved from 0.67888 to 0.67774, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6411 - val_loss: 0.6777\n",
      "Epoch 104/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6778\n",
      "Epoch 104: val_loss improved from 0.67774 to 0.67634, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6723 - val_loss: 0.6763\n",
      "Epoch 105/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6181\n",
      "Epoch 105: val_loss improved from 0.67634 to 0.67245, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6366 - val_loss: 0.6725\n",
      "Epoch 106/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6814\n",
      "Epoch 106: val_loss improved from 0.67245 to 0.66978, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6538 - val_loss: 0.6698\n",
      "Epoch 107/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6109\n",
      "Epoch 107: val_loss improved from 0.66978 to 0.66756, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6415 - val_loss: 0.6676\n",
      "Epoch 108/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6183\n",
      "Epoch 108: val_loss improved from 0.66756 to 0.66472, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6389 - val_loss: 0.6647\n",
      "Epoch 109/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6275\n",
      "Epoch 109: val_loss improved from 0.66472 to 0.66319, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6283 - val_loss: 0.6632\n",
      "Epoch 110/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6102\n",
      "Epoch 110: val_loss improved from 0.66319 to 0.66189, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6290 - val_loss: 0.6619\n",
      "Epoch 111/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6440\n",
      "Epoch 111: val_loss improved from 0.66189 to 0.66025, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6299 - val_loss: 0.6603\n",
      "Epoch 112/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6471\n",
      "Epoch 112: val_loss improved from 0.66025 to 0.65766, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6307 - val_loss: 0.6577\n",
      "Epoch 113/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6071\n",
      "Epoch 113: val_loss improved from 0.65766 to 0.65644, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6187 - val_loss: 0.6564\n",
      "Epoch 114/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6116\n",
      "Epoch 114: val_loss improved from 0.65644 to 0.65491, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6227 - val_loss: 0.6549\n",
      "Epoch 115/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6386\n",
      "Epoch 115: val_loss improved from 0.65491 to 0.65281, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6369 - val_loss: 0.6528\n",
      "Epoch 116/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5772\n",
      "Epoch 116: val_loss improved from 0.65281 to 0.65108, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6109 - val_loss: 0.6511\n",
      "Epoch 117/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6169\n",
      "Epoch 117: val_loss improved from 0.65108 to 0.64834, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6313 - val_loss: 0.6483\n",
      "Epoch 118/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6454\n",
      "Epoch 118: val_loss improved from 0.64834 to 0.64643, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6279 - val_loss: 0.6464\n",
      "Epoch 119/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6165\n",
      "Epoch 119: val_loss improved from 0.64643 to 0.64518, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6189 - val_loss: 0.6452\n",
      "Epoch 120/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5907\n",
      "Epoch 120: val_loss improved from 0.64518 to 0.64514, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6059 - val_loss: 0.6451\n",
      "Epoch 121/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6505\n",
      "Epoch 121: val_loss did not improve from 0.64514\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6235 - val_loss: 0.6458\n",
      "Epoch 122/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6050\n",
      "Epoch 122: val_loss improved from 0.64514 to 0.64443, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6056 - val_loss: 0.6444\n",
      "Epoch 123/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6055\n",
      "Epoch 123: val_loss improved from 0.64443 to 0.64256, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6066 - val_loss: 0.6426\n",
      "Epoch 124/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6089\n",
      "Epoch 124: val_loss improved from 0.64256 to 0.64048, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6131 - val_loss: 0.6405\n",
      "Epoch 125/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6280\n",
      "Epoch 125: val_loss improved from 0.64048 to 0.63922, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6219 - val_loss: 0.6392\n",
      "Epoch 126/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6063\n",
      "Epoch 126: val_loss improved from 0.63922 to 0.63804, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6098 - val_loss: 0.6380\n",
      "Epoch 127/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5816\n",
      "Epoch 127: val_loss improved from 0.63804 to 0.63709, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5935 - val_loss: 0.6371\n",
      "Epoch 128/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6160\n",
      "Epoch 128: val_loss improved from 0.63709 to 0.63391, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6062 - val_loss: 0.6339\n",
      "Epoch 129/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5936\n",
      "Epoch 129: val_loss improved from 0.63391 to 0.63240, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6085 - val_loss: 0.6324\n",
      "Epoch 130/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5750\n",
      "Epoch 130: val_loss improved from 0.63240 to 0.63155, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5984 - val_loss: 0.6315\n",
      "Epoch 131/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6111\n",
      "Epoch 131: val_loss improved from 0.63155 to 0.62827, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6082 - val_loss: 0.6283\n",
      "Epoch 132/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6252\n",
      "Epoch 132: val_loss improved from 0.62827 to 0.62677, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6049 - val_loss: 0.6268\n",
      "Epoch 133/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6090\n",
      "Epoch 133: val_loss improved from 0.62677 to 0.62510, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6037 - val_loss: 0.6251\n",
      "Epoch 134/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6220\n",
      "Epoch 134: val_loss improved from 0.62510 to 0.62504, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6000 - val_loss: 0.6250\n",
      "Epoch 135/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5853\n",
      "Epoch 135: val_loss improved from 0.62504 to 0.62301, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5900 - val_loss: 0.6230\n",
      "Epoch 136/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6104\n",
      "Epoch 136: val_loss improved from 0.62301 to 0.62146, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5961 - val_loss: 0.6215\n",
      "Epoch 137/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6032\n",
      "Epoch 137: val_loss improved from 0.62146 to 0.62005, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5931 - val_loss: 0.6200\n",
      "Epoch 138/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5774\n",
      "Epoch 138: val_loss improved from 0.62005 to 0.61855, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5818 - val_loss: 0.6185\n",
      "Epoch 139/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5895\n",
      "Epoch 139: val_loss improved from 0.61855 to 0.61797, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5861 - val_loss: 0.6180\n",
      "Epoch 140/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5865\n",
      "Epoch 140: val_loss improved from 0.61797 to 0.61655, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5873 - val_loss: 0.6166\n",
      "Epoch 141/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5547\n",
      "Epoch 141: val_loss improved from 0.61655 to 0.61601, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5842 - val_loss: 0.6160\n",
      "Epoch 142/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5518\n",
      "Epoch 142: val_loss improved from 0.61601 to 0.61476, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5927 - val_loss: 0.6148\n",
      "Epoch 143/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5795\n",
      "Epoch 143: val_loss improved from 0.61476 to 0.61347, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5801 - val_loss: 0.6135\n",
      "Epoch 144/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5815\n",
      "Epoch 144: val_loss improved from 0.61347 to 0.61147, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5750 - val_loss: 0.6115\n",
      "Epoch 145/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5744\n",
      "Epoch 145: val_loss improved from 0.61147 to 0.60901, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5756 - val_loss: 0.6090\n",
      "Epoch 146/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5841\n",
      "Epoch 146: val_loss improved from 0.60901 to 0.60690, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5759 - val_loss: 0.6069\n",
      "Epoch 147/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5737\n",
      "Epoch 147: val_loss improved from 0.60690 to 0.60533, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5815 - val_loss: 0.6053\n",
      "Epoch 148/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5805\n",
      "Epoch 148: val_loss improved from 0.60533 to 0.60327, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5747 - val_loss: 0.6033\n",
      "Epoch 149/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5644\n",
      "Epoch 149: val_loss improved from 0.60327 to 0.60296, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5691 - val_loss: 0.6030\n",
      "Epoch 150/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6241\n",
      "Epoch 150: val_loss improved from 0.60296 to 0.60089, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5827 - val_loss: 0.6009\n",
      "Epoch 151/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5527\n",
      "Epoch 151: val_loss improved from 0.60089 to 0.59865, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5643 - val_loss: 0.5987\n",
      "Epoch 152/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5941\n",
      "Epoch 152: val_loss improved from 0.59865 to 0.59755, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5673 - val_loss: 0.5976\n",
      "Epoch 153/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5626\n",
      "Epoch 153: val_loss improved from 0.59755 to 0.59559, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5723 - val_loss: 0.5956\n",
      "Epoch 154/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5536\n",
      "Epoch 154: val_loss improved from 0.59559 to 0.59349, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5557 - val_loss: 0.5935\n",
      "Epoch 155/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5907\n",
      "Epoch 155: val_loss improved from 0.59349 to 0.59179, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5705 - val_loss: 0.5918\n",
      "Epoch 156/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5398\n",
      "Epoch 156: val_loss improved from 0.59179 to 0.59088, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5635 - val_loss: 0.5909\n",
      "Epoch 157/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5383\n",
      "Epoch 157: val_loss improved from 0.59088 to 0.58906, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5646 - val_loss: 0.5891\n",
      "Epoch 158/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5554\n",
      "Epoch 158: val_loss improved from 0.58906 to 0.58695, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5817 - val_loss: 0.5869\n",
      "Epoch 159/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5911\n",
      "Epoch 159: val_loss improved from 0.58695 to 0.58653, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5665 - val_loss: 0.5865\n",
      "Epoch 160/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5367\n",
      "Epoch 160: val_loss improved from 0.58653 to 0.58566, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5494 - val_loss: 0.5857\n",
      "Epoch 161/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5707\n",
      "Epoch 161: val_loss improved from 0.58566 to 0.58562, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5629 - val_loss: 0.5856\n",
      "Epoch 162/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5975\n",
      "Epoch 162: val_loss improved from 0.58562 to 0.58408, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5687 - val_loss: 0.5841\n",
      "Epoch 163/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5501\n",
      "Epoch 163: val_loss improved from 0.58408 to 0.58342, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5637 - val_loss: 0.5834\n",
      "Epoch 164/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5472\n",
      "Epoch 164: val_loss improved from 0.58342 to 0.58146, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5464 - val_loss: 0.5815\n",
      "Epoch 165/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5513\n",
      "Epoch 165: val_loss improved from 0.58146 to 0.57895, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5496 - val_loss: 0.5790\n",
      "Epoch 166/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5354\n",
      "Epoch 166: val_loss improved from 0.57895 to 0.57637, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5610 - val_loss: 0.5764\n",
      "Epoch 167/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5345\n",
      "Epoch 167: val_loss improved from 0.57637 to 0.57440, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5487 - val_loss: 0.5744\n",
      "Epoch 168/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5388\n",
      "Epoch 168: val_loss improved from 0.57440 to 0.57360, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5502 - val_loss: 0.5736\n",
      "Epoch 169/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5272\n",
      "Epoch 169: val_loss improved from 0.57360 to 0.57272, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5428 - val_loss: 0.5727\n",
      "Epoch 170/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5221\n",
      "Epoch 170: val_loss improved from 0.57272 to 0.57194, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5323 - val_loss: 0.5719\n",
      "Epoch 171/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5573\n",
      "Epoch 171: val_loss improved from 0.57194 to 0.57099, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5478 - val_loss: 0.5710\n",
      "Epoch 172/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5409\n",
      "Epoch 172: val_loss did not improve from 0.57099\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5522 - val_loss: 0.5712\n",
      "Epoch 173/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5159\n",
      "Epoch 173: val_loss improved from 0.57099 to 0.57044, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5360 - val_loss: 0.5704\n",
      "Epoch 174/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5234\n",
      "Epoch 174: val_loss improved from 0.57044 to 0.56823, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5420 - val_loss: 0.5682\n",
      "Epoch 175/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5274\n",
      "Epoch 175: val_loss improved from 0.56823 to 0.56559, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5384 - val_loss: 0.5656\n",
      "Epoch 176/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5291\n",
      "Epoch 176: val_loss improved from 0.56559 to 0.56504, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5339 - val_loss: 0.5650\n",
      "Epoch 177/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5042\n",
      "Epoch 177: val_loss improved from 0.56504 to 0.56392, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5208 - val_loss: 0.5639\n",
      "Epoch 178/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5112\n",
      "Epoch 178: val_loss improved from 0.56392 to 0.56289, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5430 - val_loss: 0.5629\n",
      "Epoch 179/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5422\n",
      "Epoch 179: val_loss improved from 0.56289 to 0.56284, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5524 - val_loss: 0.5628\n",
      "Epoch 180/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5112\n",
      "Epoch 180: val_loss did not improve from 0.56284\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5274 - val_loss: 0.5641\n",
      "Epoch 181/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5279\n",
      "Epoch 181: val_loss improved from 0.56284 to 0.56217, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5392 - val_loss: 0.5622\n",
      "Epoch 182/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5407\n",
      "Epoch 182: val_loss improved from 0.56217 to 0.56003, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5360 - val_loss: 0.5600\n",
      "Epoch 183/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5289\n",
      "Epoch 183: val_loss improved from 0.56003 to 0.55828, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5261 - val_loss: 0.5583\n",
      "Epoch 184/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5373\n",
      "Epoch 184: val_loss improved from 0.55828 to 0.55653, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5324 - val_loss: 0.5565\n",
      "Epoch 185/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5183\n",
      "Epoch 185: val_loss improved from 0.55653 to 0.55495, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5212 - val_loss: 0.5549\n",
      "Epoch 186/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5137\n",
      "Epoch 186: val_loss improved from 0.55495 to 0.55420, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5311 - val_loss: 0.5542\n",
      "Epoch 187/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5452\n",
      "Epoch 187: val_loss improved from 0.55420 to 0.55299, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5298 - val_loss: 0.5530\n",
      "Epoch 188/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5368\n",
      "Epoch 188: val_loss improved from 0.55299 to 0.55172, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5338 - val_loss: 0.5517\n",
      "Epoch 189/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5192\n",
      "Epoch 189: val_loss improved from 0.55172 to 0.54926, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5215 - val_loss: 0.5493\n",
      "Epoch 190/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5155\n",
      "Epoch 190: val_loss improved from 0.54926 to 0.54789, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5215 - val_loss: 0.5479\n",
      "Epoch 191/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5427\n",
      "Epoch 191: val_loss improved from 0.54789 to 0.54590, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5392 - val_loss: 0.5459\n",
      "Epoch 192/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5872\n",
      "Epoch 192: val_loss improved from 0.54590 to 0.54538, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5427 - val_loss: 0.5454\n",
      "Epoch 193/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5178\n",
      "Epoch 193: val_loss improved from 0.54538 to 0.54456, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5278 - val_loss: 0.5446\n",
      "Epoch 194/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5033\n",
      "Epoch 194: val_loss improved from 0.54456 to 0.54372, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5165 - val_loss: 0.5437\n",
      "Epoch 195/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4860\n",
      "Epoch 195: val_loss improved from 0.54372 to 0.54289, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5067 - val_loss: 0.5429\n",
      "Epoch 196/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5019\n",
      "Epoch 196: val_loss improved from 0.54289 to 0.54104, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5078 - val_loss: 0.5410\n",
      "Epoch 197/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5204\n",
      "Epoch 197: val_loss improved from 0.54104 to 0.53957, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5139 - val_loss: 0.5396\n",
      "Epoch 198/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4917\n",
      "Epoch 198: val_loss improved from 0.53957 to 0.53930, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5142 - val_loss: 0.5393\n",
      "Epoch 199/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5135\n",
      "Epoch 199: val_loss improved from 0.53930 to 0.53774, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5085 - val_loss: 0.5377\n",
      "Epoch 200/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5189\n",
      "Epoch 200: val_loss did not improve from 0.53774\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5243 - val_loss: 0.5378\n",
      "Epoch 201/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5370\n",
      "Epoch 201: val_loss improved from 0.53774 to 0.53713, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5161 - val_loss: 0.5371\n",
      "Epoch 202/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4999\n",
      "Epoch 202: val_loss improved from 0.53713 to 0.53529, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5022 - val_loss: 0.5353\n",
      "Epoch 203/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5595\n",
      "Epoch 203: val_loss improved from 0.53529 to 0.53316, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5200 - val_loss: 0.5332\n",
      "Epoch 204/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5254\n",
      "Epoch 204: val_loss improved from 0.53316 to 0.53183, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5143 - val_loss: 0.5318\n",
      "Epoch 205/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5104\n",
      "Epoch 205: val_loss improved from 0.53183 to 0.53154, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5066 - val_loss: 0.5315\n",
      "Epoch 206/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4791\n",
      "Epoch 206: val_loss improved from 0.53154 to 0.53129, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5042 - val_loss: 0.5313\n",
      "Epoch 207/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5112\n",
      "Epoch 207: val_loss improved from 0.53129 to 0.52969, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5059 - val_loss: 0.5297\n",
      "Epoch 208/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4934\n",
      "Epoch 208: val_loss improved from 0.52969 to 0.52805, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5050 - val_loss: 0.5280\n",
      "Epoch 209/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4805\n",
      "Epoch 209: val_loss improved from 0.52805 to 0.52744, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5078 - val_loss: 0.5274\n",
      "Epoch 210/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4794\n",
      "Epoch 210: val_loss improved from 0.52744 to 0.52656, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4988 - val_loss: 0.5266\n",
      "Epoch 211/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5110\n",
      "Epoch 211: val_loss improved from 0.52656 to 0.52649, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5025 - val_loss: 0.5265\n",
      "Epoch 212/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4920\n",
      "Epoch 212: val_loss improved from 0.52649 to 0.52628, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4914 - val_loss: 0.5263\n",
      "Epoch 213/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5003\n",
      "Epoch 213: val_loss improved from 0.52628 to 0.52488, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4975 - val_loss: 0.5249\n",
      "Epoch 214/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4939\n",
      "Epoch 214: val_loss improved from 0.52488 to 0.52246, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5073 - val_loss: 0.5225\n",
      "Epoch 215/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4832\n",
      "Epoch 215: val_loss improved from 0.52246 to 0.51939, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4891 - val_loss: 0.5194\n",
      "Epoch 216/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4541\n",
      "Epoch 216: val_loss improved from 0.51939 to 0.51725, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4882 - val_loss: 0.5173\n",
      "Epoch 217/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5178\n",
      "Epoch 217: val_loss did not improve from 0.51725\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4969 - val_loss: 0.5180\n",
      "Epoch 218/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4806\n",
      "Epoch 218: val_loss did not improve from 0.51725\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4945 - val_loss: 0.5182\n",
      "Epoch 219/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4603\n",
      "Epoch 219: val_loss did not improve from 0.51725\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4895 - val_loss: 0.5178\n",
      "Epoch 220/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5225\n",
      "Epoch 220: val_loss improved from 0.51725 to 0.51675, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5037 - val_loss: 0.5167\n",
      "Epoch 221/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5037\n",
      "Epoch 221: val_loss improved from 0.51675 to 0.51605, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4967 - val_loss: 0.5160\n",
      "Epoch 222/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5074\n",
      "Epoch 222: val_loss did not improve from 0.51605\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4931 - val_loss: 0.5162\n",
      "Epoch 223/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5023\n",
      "Epoch 223: val_loss improved from 0.51605 to 0.51378, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4875 - val_loss: 0.5138\n",
      "Epoch 224/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4811\n",
      "Epoch 224: val_loss improved from 0.51378 to 0.51311, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4848 - val_loss: 0.5131\n",
      "Epoch 225/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4590\n",
      "Epoch 225: val_loss improved from 0.51311 to 0.51276, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4736 - val_loss: 0.5128\n",
      "Epoch 226/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4911\n",
      "Epoch 226: val_loss improved from 0.51276 to 0.51089, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4846 - val_loss: 0.5109\n",
      "Epoch 227/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4613\n",
      "Epoch 227: val_loss improved from 0.51089 to 0.50946, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4781 - val_loss: 0.5095\n",
      "Epoch 228/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5112\n",
      "Epoch 228: val_loss improved from 0.50946 to 0.50804, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4848 - val_loss: 0.5080\n",
      "Epoch 229/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4606\n",
      "Epoch 229: val_loss improved from 0.50804 to 0.50606, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4840 - val_loss: 0.5061\n",
      "Epoch 230/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4704\n",
      "Epoch 230: val_loss improved from 0.50606 to 0.50527, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4809 - val_loss: 0.5053\n",
      "Epoch 231/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4614\n",
      "Epoch 231: val_loss improved from 0.50527 to 0.50452, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4866 - val_loss: 0.5045\n",
      "Epoch 232/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4785\n",
      "Epoch 232: val_loss improved from 0.50452 to 0.50407, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4840 - val_loss: 0.5041\n",
      "Epoch 233/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4611\n",
      "Epoch 233: val_loss improved from 0.50407 to 0.50282, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4754 - val_loss: 0.5028\n",
      "Epoch 234/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4556\n",
      "Epoch 234: val_loss improved from 0.50282 to 0.50135, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4782 - val_loss: 0.5013\n",
      "Epoch 235/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4537\n",
      "Epoch 235: val_loss improved from 0.50135 to 0.50067, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4678 - val_loss: 0.5007\n",
      "Epoch 236/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5017\n",
      "Epoch 236: val_loss improved from 0.50067 to 0.49971, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4819 - val_loss: 0.4997\n",
      "Epoch 237/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4570\n",
      "Epoch 237: val_loss improved from 0.49971 to 0.49880, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4718 - val_loss: 0.4988\n",
      "Epoch 238/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4723\n",
      "Epoch 238: val_loss improved from 0.49880 to 0.49829, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4748 - val_loss: 0.4983\n",
      "Epoch 239/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4523\n",
      "Epoch 239: val_loss improved from 0.49829 to 0.49748, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4663 - val_loss: 0.4975\n",
      "Epoch 240/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4575\n",
      "Epoch 240: val_loss improved from 0.49748 to 0.49589, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4775 - val_loss: 0.4959\n",
      "Epoch 241/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4416\n",
      "Epoch 241: val_loss improved from 0.49589 to 0.49433, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4594 - val_loss: 0.4943\n",
      "Epoch 242/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4687\n",
      "Epoch 242: val_loss improved from 0.49433 to 0.49359, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4635 - val_loss: 0.4936\n",
      "Epoch 243/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4517\n",
      "Epoch 243: val_loss improved from 0.49359 to 0.49263, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4619 - val_loss: 0.4926\n",
      "Epoch 244/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4686\n",
      "Epoch 244: val_loss improved from 0.49263 to 0.49122, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4733 - val_loss: 0.4912\n",
      "Epoch 245/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4663\n",
      "Epoch 245: val_loss improved from 0.49122 to 0.48960, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4622 - val_loss: 0.4896\n",
      "Epoch 246/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4847\n",
      "Epoch 246: val_loss improved from 0.48960 to 0.48905, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4761 - val_loss: 0.4891\n",
      "Epoch 247/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4778\n",
      "Epoch 247: val_loss improved from 0.48905 to 0.48839, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4627 - val_loss: 0.4884\n",
      "Epoch 248/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4483\n",
      "Epoch 248: val_loss improved from 0.48839 to 0.48643, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4513 - val_loss: 0.4864\n",
      "Epoch 249/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4821\n",
      "Epoch 249: val_loss improved from 0.48643 to 0.48509, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4703 - val_loss: 0.4851\n",
      "Epoch 250/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4591\n",
      "Epoch 250: val_loss improved from 0.48509 to 0.48384, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4553 - val_loss: 0.4838\n",
      "Epoch 251/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4495\n",
      "Epoch 251: val_loss did not improve from 0.48384\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4504 - val_loss: 0.4843\n",
      "Epoch 252/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4804\n",
      "Epoch 252: val_loss did not improve from 0.48384\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4559 - val_loss: 0.4846\n",
      "Epoch 253/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4331\n",
      "Epoch 253: val_loss improved from 0.48384 to 0.48286, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4555 - val_loss: 0.4829\n",
      "Epoch 254/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4532\n",
      "Epoch 254: val_loss improved from 0.48286 to 0.48095, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4468 - val_loss: 0.4809\n",
      "Epoch 255/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4975\n",
      "Epoch 255: val_loss improved from 0.48095 to 0.47967, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4719 - val_loss: 0.4797\n",
      "Epoch 256/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4571\n",
      "Epoch 256: val_loss improved from 0.47967 to 0.47780, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4614 - val_loss: 0.4778\n",
      "Epoch 257/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4490\n",
      "Epoch 257: val_loss improved from 0.47780 to 0.47594, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4539 - val_loss: 0.4759\n",
      "Epoch 258/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4693\n",
      "Epoch 258: val_loss improved from 0.47594 to 0.47537, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4567 - val_loss: 0.4754\n",
      "Epoch 259/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4317\n",
      "Epoch 259: val_loss did not improve from 0.47537\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4439 - val_loss: 0.4762\n",
      "Epoch 260/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4463\n",
      "Epoch 260: val_loss improved from 0.47537 to 0.47480, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4595 - val_loss: 0.4748\n",
      "Epoch 261/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4289\n",
      "Epoch 261: val_loss improved from 0.47480 to 0.47467, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4447 - val_loss: 0.4747\n",
      "Epoch 262/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4283\n",
      "Epoch 262: val_loss improved from 0.47467 to 0.47370, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4585 - val_loss: 0.4737\n",
      "Epoch 263/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4573\n",
      "Epoch 263: val_loss improved from 0.47370 to 0.47243, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4508 - val_loss: 0.4724\n",
      "Epoch 264/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4353\n",
      "Epoch 264: val_loss improved from 0.47243 to 0.47003, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4520 - val_loss: 0.4700\n",
      "Epoch 265/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4254\n",
      "Epoch 265: val_loss improved from 0.47003 to 0.46955, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4349 - val_loss: 0.4696\n",
      "Epoch 266/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4198\n",
      "Epoch 266: val_loss improved from 0.46955 to 0.46944, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4413 - val_loss: 0.4694\n",
      "Epoch 267/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4326\n",
      "Epoch 267: val_loss improved from 0.46944 to 0.46822, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4413 - val_loss: 0.4682\n",
      "Epoch 268/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4334\n",
      "Epoch 268: val_loss improved from 0.46822 to 0.46768, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4352 - val_loss: 0.4677\n",
      "Epoch 269/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4202\n",
      "Epoch 269: val_loss improved from 0.46768 to 0.46649, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4424 - val_loss: 0.4665\n",
      "Epoch 270/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4601\n",
      "Epoch 270: val_loss improved from 0.46649 to 0.46518, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4447 - val_loss: 0.4652\n",
      "Epoch 271/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4609\n",
      "Epoch 271: val_loss improved from 0.46518 to 0.46456, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4505 - val_loss: 0.4646\n",
      "Epoch 272/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4604\n",
      "Epoch 272: val_loss improved from 0.46456 to 0.46364, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4488 - val_loss: 0.4636\n",
      "Epoch 273/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4378\n",
      "Epoch 273: val_loss improved from 0.46364 to 0.46224, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4357 - val_loss: 0.4622\n",
      "Epoch 274/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4189\n",
      "Epoch 274: val_loss improved from 0.46224 to 0.46095, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4391 - val_loss: 0.4610\n",
      "Epoch 275/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4537\n",
      "Epoch 275: val_loss improved from 0.46095 to 0.45939, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4373 - val_loss: 0.4594\n",
      "Epoch 276/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4391\n",
      "Epoch 276: val_loss improved from 0.45939 to 0.45809, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4368 - val_loss: 0.4581\n",
      "Epoch 277/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4466\n",
      "Epoch 277: val_loss improved from 0.45809 to 0.45670, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4510 - val_loss: 0.4567\n",
      "Epoch 278/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4149\n",
      "Epoch 278: val_loss improved from 0.45670 to 0.45663, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4236 - val_loss: 0.4566\n",
      "Epoch 279/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4453\n",
      "Epoch 279: val_loss improved from 0.45663 to 0.45532, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4470 - val_loss: 0.4553\n",
      "Epoch 280/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4234\n",
      "Epoch 280: val_loss improved from 0.45532 to 0.45428, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4277 - val_loss: 0.4543\n",
      "Epoch 281/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4064\n",
      "Epoch 281: val_loss improved from 0.45428 to 0.45339, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4275 - val_loss: 0.4534\n",
      "Epoch 282/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4230\n",
      "Epoch 282: val_loss improved from 0.45339 to 0.45327, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4284 - val_loss: 0.4533\n",
      "Epoch 283/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4432\n",
      "Epoch 283: val_loss improved from 0.45327 to 0.45275, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4370 - val_loss: 0.4528\n",
      "Epoch 284/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4276\n",
      "Epoch 284: val_loss improved from 0.45275 to 0.45192, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4295 - val_loss: 0.4519\n",
      "Epoch 285/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4188\n",
      "Epoch 285: val_loss improved from 0.45192 to 0.45034, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4284 - val_loss: 0.4503\n",
      "Epoch 286/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4259\n",
      "Epoch 286: val_loss improved from 0.45034 to 0.45002, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4349 - val_loss: 0.4500\n",
      "Epoch 287/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4205\n",
      "Epoch 287: val_loss improved from 0.45002 to 0.44943, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4306 - val_loss: 0.4494\n",
      "Epoch 288/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4454\n",
      "Epoch 288: val_loss improved from 0.44943 to 0.44841, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4416 - val_loss: 0.4484\n",
      "Epoch 289/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4125\n",
      "Epoch 289: val_loss improved from 0.44841 to 0.44691, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4236 - val_loss: 0.4469\n",
      "Epoch 290/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4061\n",
      "Epoch 290: val_loss improved from 0.44691 to 0.44502, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4203 - val_loss: 0.4450\n",
      "Epoch 291/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4172\n",
      "Epoch 291: val_loss improved from 0.44502 to 0.44272, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4177 - val_loss: 0.4427\n",
      "Epoch 292/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3960\n",
      "Epoch 292: val_loss improved from 0.44272 to 0.44178, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4123 - val_loss: 0.4418\n",
      "Epoch 293/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4331\n",
      "Epoch 293: val_loss improved from 0.44178 to 0.44154, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4249 - val_loss: 0.4415\n",
      "Epoch 294/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4013\n",
      "Epoch 294: val_loss improved from 0.44154 to 0.44117, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4129 - val_loss: 0.4412\n",
      "Epoch 295/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4203\n",
      "Epoch 295: val_loss improved from 0.44117 to 0.44028, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4249 - val_loss: 0.4403\n",
      "Epoch 296/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3980\n",
      "Epoch 296: val_loss improved from 0.44028 to 0.43979, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4119 - val_loss: 0.4398\n",
      "Epoch 297/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.4103\n",
      "Epoch 297: val_loss improved from 0.43979 to 0.43926, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4146 - val_loss: 0.4393\n",
      "Epoch 298/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3849\n",
      "Epoch 298: val_loss improved from 0.43926 to 0.43682, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4060 - val_loss: 0.4368\n",
      "Epoch 299/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3986\n",
      "Epoch 299: val_loss improved from 0.43682 to 0.43517, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4098 - val_loss: 0.4352\n",
      "Epoch 300/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4071\n",
      "Epoch 300: val_loss improved from 0.43517 to 0.43399, saving model to models/ae.weights.h5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4096 - val_loss: 0.4340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = ae.fit(\n",
    "    X_train_array_ae,\n",
    "    X_train_array_ae,\n",
    "    batch_size=20,\n",
    "    epochs=300,\n",
    "    validation_data=(X_test_array_ae, X_test_array_ae),\n",
    "    verbose=1,\n",
    "    callbacks=[m_ch,]\n",
    ")\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.load_weights('models/ae.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.0041558 ,  0.07256062,  0.07299767,  0.27954596,  0.8574281 ,\n",
       "       -0.04625408,  0.17849809,  0.11333622,  0.8993934 , -0.20964625,\n",
       "        1.1319356 ,  0.32250768,  0.25235957, -1.185437  ,  1.211183  ,\n",
       "        0.5338946 ,  0.5521431 ,  0.24509533,  0.5874618 ,  0.04869885],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.predict(X_test_array_ae)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18051574, 0.16448244, 0.20213732, 0.20280516, 0.4246544 ,\n",
       "       0.25046414, 0.26430535, 0.20079891, 0.18564999, 0.39777574,\n",
       "       0.17953944, 0.23599248, 0.19300196, 0.30468526, 0.23194873,\n",
       "       0.17492807, 0.43299198, 0.30737814, 0.21751365, 0.2692039 ,\n",
       "       0.15873882, 0.40256128, 0.3445053 , 0.2740209 , 0.22779398,\n",
       "       0.13037768, 0.2668004 , 0.28775677, 0.14374371, 0.16997485,\n",
       "       0.19036564, 0.17502731, 0.13804868, 0.30678263, 0.21879634,\n",
       "       0.37217784, 0.27873826, 0.39889577, 0.29891986, 0.1972179 ,\n",
       "       0.26197138, 0.12940493, 0.31087494, 0.34212106, 0.39825106,\n",
       "       0.17785569, 0.1942487 , 0.3606307 , 0.22384813, 0.2659815 ,\n",
       "       0.20175175], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(X_test_array_ae, ae.predict(X_test_array_ae)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18051574, 0.16448244, 0.34872466, 0.20213732, 0.20280516,\n",
       "       0.4246544 , 0.25046414, 0.26430535, 0.20079891, 0.18564999,\n",
       "       0.39777574, 0.17953944, 0.23599248, 0.19300196, 0.30468526,\n",
       "       0.23194873, 0.17492807, 0.43299198, 0.30737814, 0.21315369,\n",
       "       0.21751365, 0.2692039 , 0.15873882, 0.40256128, 0.3445053 ,\n",
       "       0.2740209 , 0.22779398, 0.13037768, 0.2668004 , 0.4521196 ,\n",
       "       0.28775677, 0.14374371, 0.16997486, 0.19036558, 0.17502734,\n",
       "       0.13804862, 0.30678266, 0.21879634, 0.37217784, 0.27873817,\n",
       "       0.3988958 , 0.29891986, 0.1972178 , 0.26197132, 0.12940486,\n",
       "       0.310875  , 0.3421211 , 0.39825112, 0.17785569, 0.1942487 ,\n",
       "       0.3606307 , 0.22384815, 0.26598153, 0.20175183], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(X_test_array, ae.predict(X_test_array)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34872463, 0.21315375, 0.45211953], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(\n",
    "    preprocessor.transform(\n",
    "        X_test_df.drop(\n",
    "            Y_test_df[Y_test_df['thal'] != 1].index)\n",
    "        ), \n",
    "        ae.predict(\n",
    "            preprocessor.transform(\n",
    "                X_test_df.drop(Y_test_df[Y_test_df['thal'] != 1].index)\n",
    "            )\n",
    "        )\n",
    ").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en.predict(X_test_array).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
